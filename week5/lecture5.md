## Unsupervised Machine Learning

### üéØ Learning Objectives

By the end of this class, students will:

* Understand what unsupervised learning is and how it differs from supervised learning.
* Learn key UML techniques like clustering and dimensionality reduction.
* See applications of UML in physics (e.g. particle physics, condensed matter).
* Gain intuition on how UML finds structure in unlabeled data.

---

## 1. ü§ñ What is Unsupervised Learning?

* **Definition:** Machine learning where the algorithm is given data *without labels* and tries to discover structure on its own.

| Aspect  | Supervised Learning      | Unsupervised Learning                |
| ------- | ------------------------ | ------------------------------------ |
| Input   | Features + Labels        | Only Features                        |
| Goal    | Predict or classify      | Discover structure/patterns          |
| Example | Predict energy from mass | Find particle clusters in a detector |

---

## 2. üîç Common Unsupervised Learning Techniques

### A. Clustering

* **Goal:** Group data points that are ‚Äúsimilar‚Äù to each other.
* **Analogy (Physics):** Imagine dropping iron filings around a magnet‚Äîclusters form naturally due to a field.
* **Techniques:**

  * **K-Means:** Assumes data form spherical clusters.
  * **DBSCAN:** Can find non-spherical clusters and noise.
  * **Hierarchical Clustering:** Builds a tree-like structure.


### B. Dimensionality Reduction

* **Goal:** Compress data while preserving important structures.
* **Analogy (Physics):** Think of reducing a complex potential energy surface into a few dominant modes.
* **Techniques:**

  * **PCA (Principal Component Analysis):** Linear, finds orthogonal directions of variance.
  * **t-SNE / UMAP:** Nonlinear, great for visualizing high-dimensional data in 2D or 3D.



---
## 3. üìä Practical Example

#### Unsupervised Machine Learning in Electromagnetics:

In electromagnetics, the electric field E generated by point charges varies spatially and can be measured at different locations in space. In this problem, imagine a two-dimensional region where several unknown point charges are present. We do not know how many charges exist, their locations, or their magnitudes. However, we are able to measure the magnitude of the electric field at various positions across a uniform grid in this region.

* Electric field values are generated using the inverse-square law for multiple point charges:

$$
|E(x, y)| = \sum_{i=1}^N \frac{q_i}{(x - x_i)^2 + (y - y_i)^2 + \epsilon}
$$

  where $(x_i, y_i)$ and $q_i$ are the unknown locations and magnitudes of the point charges, and $\epsilon$ is a small constant to avoid singularities.

* The data consists of:

  * Grid positions $(x, y)$
  * Corresponding electric field magnitude $|E|$


Your task is to use unsupervised machine learning to analyze this synthetic dataset and discover the underlying structure ‚Äî specifically:

   - Identify regions of concentrated electric field strength, which may correspond to the locations of the point charges.
   - Determine the number and possible positions of the sources using a clustering algorithm.
   - Visualize the field and clustering results to interpret the physical meaning of the clusters.
   - Optionally, reduce the dimensionality of the feature space using PCA and visualize the transformed data.

### üß† Approach:

1. **Combine the spatial coordinates and field values** into a feature vector for each point.
2. **Normalize the data** using standard scaling to ensure fair treatment of all features.
3. Apply **DBSCAN** (Density-Based Spatial Clustering of Applications with Noise), which does not require the number of clusters to be known in advance.
4. Use **PCA** to reduce the dimensionality for visualization and interpret clustering in reduced space.


```
# ----------------------------
# Step 0: import packages
# ----------------------------
import numpy as np, pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import DBSCAN
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# ----------------------------
# Step 1: Link your Google Drive to Colab and read the data
# ----------------------------

from google.colab import drive
drive.mount('/content/drive')
df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/electric_field_data.csv")
df.head(10)

# ----------------------------
# Step 2: Visualize the data
# ----------------------------
X = df['x'].values.reshape(100, 100)
Y = df['y'].values.reshape(100, 100)
E = df['E'].values.reshape(100, 100)

plt.figure(figsize=(8, 6))
contour = plt.contourf(X,Y,E, levels=50, cmap='plasma')
plt.colorbar(contour, label='|E| Field Strength')
plt.title('Electric Field Magnitude from Point Charges')
plt.xlabel('x')
plt.ylabel('y')
plt.grid(True)
plt.show()

# ----------------------------
# Step 3: Apply DBSCAN Clustering
# ----------------------------

positions = np.vstack([X.ravel(), Y.ravel()]).T
fields = E.ravel().reshape(-1, 1)
features = np.hstack([positions, fields])

scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

db = DBSCAN(eps=0.3, min_samples=10)
labels = db.fit_predict(features_scaled)

# ----------------------------
# Step 4: Plot the clustering results
# ----------------------------
plt.figure(figsize=(8, 6))
plt.scatter(X.ravel(), Y.ravel(), c=labels, cmap='tab10', s=5)
plt.title('DBSCAN Clustering on E-field Data')
plt.xlabel('x')
plt.ylabel('y')
plt.grid(True)
plt.show()
# ----------------------------
# Step 5: PCA for Dimensionality Reduction
# ----------------------------
pca = PCA(n_components=2)
features_pca = pca.fit_transform(features_scaled)

plt.figure(figsize=(8, 6))
plt.scatter(features_pca[:, 0], features_pca[:, 1], c=labels, cmap='tab10', s=5)
plt.title('PCA of E-Field Data (Colored by Cluster)')
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.grid(True)
plt.show()
```

---

## 4. üß™ Applications in Physics

| Field            | UML Application Example                                   |
| ---------------- | --------------------------------------------------------- |
| Particle Physics | Jet detection, anomaly detection at CERN                  |
| Condensed Matter | Phase classification from spin configurations             |
| Astrophysics     | Grouping galaxies by morphology (unsupervised clustering) |
| Quantum Systems  | Discovering hidden phases in Hamiltonian data             |

---

## 5. üß† Key Takeaways

* Unsupervised learning helps uncover hidden patterns without needing labels.
* Clustering = finding groups; dimensionality reduction = simplifying complexity.
* It complements physics: physics suggests structure; UML finds it when it‚Äôs not obvious.
* **Physicists already think like data scientists!** UML just provides new tools.

---

## 6. üìö Suggested Reading & Tools

* **Books:**

  * *"The Elements of Statistical Learning"* by Hastie, Tibshirani, and Friedman.
  * *"Machine Learning for Physicists"* by Mehta et al.
* **Tools:**

  * Python libraries: `scikit-learn`, `matplotlib`, `seaborn`
  * Jupyter Notebooks for interactive exploration

---

## üß© Homework for Students

1. Load a dataset (e.g., MNIST or particle collisions) and apply PCA to visualize in 2D.
2. Use K-Means to cluster simulated detector data‚Äîhow does the clustering change with noise?
3. Read a paper where unsupervised learning is used in physics‚Äîsummarize the method and result.

---
